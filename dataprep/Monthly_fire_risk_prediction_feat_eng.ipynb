{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbfa666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbb9a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[input exists?] True ‚ûú C:\\Users\\mirei\\OneDrive\\Desktop\\all-capstone-project-summer-2025-team-6-main\\datasets\\cleaned\\building_month_fire_panel_feat_eng.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# üîß Project root directory (2 levels up from current script)\n",
    "ROOT = Path.cwd().parents[0]\n",
    "\n",
    "# üîπ Define input/output paths using ROOT\n",
    "INPUT_CSV = ROOT / \"datasets\" / \"cleaned\" / \"building_month_fire_panel_feat_eng.csv\"\n",
    "#OUTPUT_PANEL = ROOT / \"datasets\" / \"cleaned\" / \"building_month_fire_panel_feat_eng.csv\"\n",
    "\n",
    "# üîç Optional: check existence\n",
    "print(\"[input exists?]\", INPUT_CSV.exists(), \"‚ûú\", INPUT_CSV)\n",
    "#print(\"[output dir exists?]\", OUTPUT_PANEL.parent.exists(), \"‚ûú\", OUTPUT_PANEL.parent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b680082b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_UEV</th>\n",
       "      <th>month</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>MUNICIPALITE</th>\n",
       "      <th>ETAGE_HORS_SOL</th>\n",
       "      <th>NOMBRE_LOGEMENT</th>\n",
       "      <th>AGE_BATIMENT</th>\n",
       "      <th>CODE_UTILISATION</th>\n",
       "      <th>CATEGORIE_UEF</th>\n",
       "      <th>...</th>\n",
       "      <th>fire_last_2m</th>\n",
       "      <th>fire_last_3m</th>\n",
       "      <th>fire_cumcount</th>\n",
       "      <th>fire_rolling_3m</th>\n",
       "      <th>fire_rolling_6m</th>\n",
       "      <th>fire_rolling_12m</th>\n",
       "      <th>has_fire_last_month</th>\n",
       "      <th>months_since_last_fire</th>\n",
       "      <th>month_num</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000011</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>45.504105</td>\n",
       "      <td>-73.564844</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>1000</td>\n",
       "      <td>R√©gulier</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000011</td>\n",
       "      <td>2020-02</td>\n",
       "      <td>45.504105</td>\n",
       "      <td>-73.564844</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>1000</td>\n",
       "      <td>R√©gulier</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000011</td>\n",
       "      <td>2020-03</td>\n",
       "      <td>45.504105</td>\n",
       "      <td>-73.564844</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>1000</td>\n",
       "      <td>R√©gulier</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000011</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>45.504105</td>\n",
       "      <td>-73.564844</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>1000</td>\n",
       "      <td>R√©gulier</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011</td>\n",
       "      <td>2020-05</td>\n",
       "      <td>45.504105</td>\n",
       "      <td>-73.564844</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>1000</td>\n",
       "      <td>R√©gulier</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_UEV    month   LATITUDE  LONGITUDE  MUNICIPALITE  ETAGE_HORS_SOL  \\\n",
       "0  1000011  2020-01  45.504105 -73.564844            50             5.0   \n",
       "1  1000011  2020-02  45.504105 -73.564844            50             5.0   \n",
       "2  1000011  2020-03  45.504105 -73.564844            50             5.0   \n",
       "3  1000011  2020-04  45.504105 -73.564844            50             5.0   \n",
       "4  1000011  2020-05  45.504105 -73.564844            50             5.0   \n",
       "\n",
       "   NOMBRE_LOGEMENT  AGE_BATIMENT  CODE_UTILISATION CATEGORIE_UEF  ...  \\\n",
       "0              8.0      0.048913              1000      R√©gulier  ...   \n",
       "1              8.0      0.048913              1000      R√©gulier  ...   \n",
       "2              8.0      0.048913              1000      R√©gulier  ...   \n",
       "3              8.0      0.048913              1000      R√©gulier  ...   \n",
       "4              8.0      0.048913              1000      R√©gulier  ...   \n",
       "\n",
       "   fire_last_2m  fire_last_3m fire_cumcount  fire_rolling_3m  fire_rolling_6m  \\\n",
       "0           0.0           0.0           0.0              0.0              0.0   \n",
       "1           0.0           0.0           0.0              0.0              0.0   \n",
       "2           0.0           0.0           0.0              0.0              0.0   \n",
       "3           0.0           0.0           0.0              0.0              0.0   \n",
       "4           0.0           0.0           0.0              0.0              0.0   \n",
       "\n",
       "   fire_rolling_12m  has_fire_last_month  months_since_last_fire  month_num  \\\n",
       "0               0.0                  0.0                   999.0          1   \n",
       "1               0.0                  0.0                   999.0          2   \n",
       "2               0.0                  0.0                   999.0          3   \n",
       "3               0.0                  0.0                   999.0          4   \n",
       "4               0.0                  0.0                   999.0          5   \n",
       "\n",
       "   year  \n",
       "0  2020  \n",
       "1  2020  \n",
       "2  2020  \n",
       "3  2020  \n",
       "4  2020  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üî∏ Load and clean fire dataset\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d2798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436ba64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c0009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c341318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "769513ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.16 GiB for an array with shape (21, 20175155) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# üî∏ Load panel for modeling\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(OUTPUT_PANEL)\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID_UEV\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1765\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1762\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1763\u001b[0m         new_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index)\n\u001b[1;32m-> 1765\u001b[0m     df \u001b[38;5;241m=\u001b[39m DataFrame(col_dict, columns\u001b[38;5;241m=\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39mindex)\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    153\u001b[0m         arrays, axes, consolidate\u001b[38;5;241m=\u001b[39mconsolidate, refs\u001b[38;5;241m=\u001b[39mrefs\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2091\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2089\u001b[0m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2090\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2091\u001b[0m     mgr\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1750\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1748\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1750\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1751\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2217\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2215\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2217\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2218\u001b[0m         \u001b[38;5;28mlist\u001b[39m(group_blocks), dtype\u001b[38;5;241m=\u001b[39mdtype, can_consolidate\u001b[38;5;241m=\u001b[39m_can_consolidate\n\u001b[0;32m   2219\u001b[0m     )\n\u001b[0;32m   2220\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2249\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2246\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2248\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2249\u001b[0m new_values \u001b[38;5;241m=\u001b[39m new_values[argsort]\n\u001b[0;32m   2250\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2252\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.16 GiB for an array with shape (21, 20175155) and data type float64"
     ]
    }
   ],
   "source": [
    "# üî∏ Load panel for modeling\n",
    "df = pd.read_csv(OUTPUT_PANEL)\n",
    "df[\"month\"] = pd.to_datetime(df[\"month\"])\n",
    "df = df.sort_values([\"ID_UEV\", \"month\"])\n",
    "df[\"year\"] = df[\"month\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üî∏ Add lag features\n",
    "for lag in range(1, 4):\n",
    "    df[f\"fire_last_{lag}m\"] = (\n",
    "        df.groupby(\"ID_UEV\")[\"HAS_FIRE_THIS_MONTH\"]\n",
    "        .shift(lag)\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce109df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa0792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092123d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "features = [\n",
    "    \"MUNICIPALITE\", \"ETAGE_HORS_SOL\", \"NOMBRE_LOGEMENT\", \"AGE_BATIMENT\",\n",
    "    \"CODE_UTILISATION\", \"CATEGORIE_UEF\", \"SUPERFICIE_TERRAIN\", \"SUPERFICIE_BATIMENT\",\n",
    "    \"NO_ARROND_ILE_CUM\", \"RATIO_SURFACE\", \"DENSITE_LOGEMENT\", \"HAS_MULTIPLE_LOGEMENTS\",\n",
    "    \"FIRE_FREQUENCY_ZONE\", \"FIRE_RATE_ZONE\", \"FIRE_COUNT_LAST_YEAR_ZONE\", \"BUILDING_COUNT\",\n",
    "    \"FIRE_RATE_ZONE_NORM\", \"FIRE_COUNT_LAST_YEAR_ZONE_NORM\", \n",
    "    \"fire_last_1m\", \"fire_last_2m\", \"fire_last_3m\",\"fire_cumcount\",\"fire_rolling_3m\",\"fire_rolling_6m\",\"fire_rolling_12m\",\n",
    "    \"month_num\", \"year\"  #,\"season\"\n",
    "]\n",
    "target = \"HAS_FIRE_THIS_MONTH\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb458b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in [\"CATEGORIE_UEF\", \"NO_ARROND_ILE_CUM\"]:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccfbbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: convert in the full df\n",
    "df[\"CATEGORIE_UEF\"] = df[\"CATEGORIE_UEF\"].astype(\"category\")\n",
    "df[\"NO_ARROND_ILE_CUM\"] = df[\"NO_ARROND_ILE_CUM\"].astype(\"category\")\n",
    "\n",
    "# Now re-split\n",
    "train_df = df[df[\"year\"] <= 2023]\n",
    "test_df = df[df[\"year\"] == 2024]\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target]\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fdd2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db2885",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öñÔ∏è Class imbalance\n",
    "scale_pos_weight = (len(y_train) - y_train.sum()) / y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa203c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    enable_categorical=True,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4548ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee0c5c3",
   "metadata": {},
   "source": [
    "üîç Interpretation of Metrics (Threshold = 0.2?)\n",
    "Metric\tClass 0 (No Fire)\tClass 1 (Fire)\n",
    "Precision\t0.992\t0.027\n",
    "Recall\t0.698\t0.603\n",
    "F1-score\t0.819\t0.051\n",
    "\n",
    "üîµ High recall for fire class (1): You're catching 60% of fires, which is good for early detection.\n",
    "\n",
    "üî¥ Very low precision for fire class (1): Among the predicted fires, only 2.7% are actually fires.\n",
    "\n",
    "‚öñÔ∏è Accuracy is misleading (69%) due to imbalance (only 1.3% fires in your data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b406f",
   "metadata": {},
   "source": [
    "üéØ Interpretation\n",
    "This is typical for imbalanced binary classification:\n",
    "\n",
    "Your model is tuned toward catching more fires (high recall).\n",
    "\n",
    "But it's imprecise: many \"fire\" predictions are wrong.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54429c",
   "metadata": {},
   "source": [
    "‚úÖ What You Did Well\n",
    "Feature engineering helped improve recall for rare event (fire).\n",
    "\n",
    "Model is no longer \"lazy\" and defaulting to class 0.\n",
    "\n",
    "Good step forward for early warning/risk flagging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f599e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570545c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a704bf14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4ac53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05c241bd",
   "metadata": {},
   "source": [
    "Start from here probabibity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa849aef",
   "metadata": {},
   "source": [
    "tune the threshold and optimize the tradeoff between precision and recall using XGBoost and sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#‚úÖ 1. Predict Probabilities on Test Set\n",
    "# Predict probabilities (for class 1 = fire)\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c4acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìà 2. Plot Precision-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(thresholds, precisions[:-1], label='Precision')\n",
    "plt.plot(thresholds, recalls[:-1], label='Recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision-Recall vs Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee339d",
   "metadata": {},
   "source": [
    "it clearly shows the typical inverse relationship between precision and recall:\n",
    "\n",
    "üî∏ Recall is very high (>90%) when the threshold is low (e.g., <0.2), but precision is very low.\n",
    "\n",
    "üî∏ Precision slightly improves as threshold increases, but only becomes meaningful after ~0.8 ‚Äî at the cost of very low recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56443b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# üîß Set threshold manually\n",
    "threshold = 0.2\n",
    "y_pred_custom = (y_probs >= threshold).astype(int)\n",
    "\n",
    "# üìä Evaluate\n",
    "print(f\"üîç Classification report at threshold = {threshold}\")\n",
    "print(confusion_matrix(y_test, y_pred_custom))\n",
    "print(classification_report(y_test, y_pred_custom, digits=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4307fb",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è What This Tells You\n",
    "‚úÖ You're capturing 95.6% of actual fires (very high recall).\n",
    "\n",
    "‚ùå But 98.4% of the \"fire\" predictions are false alarms (precision = 1.6%).\n",
    "\n",
    "‚ùå Overall accuracy drops to 23% because you're labeling so many buildings as high risk.\n",
    "\n",
    "üìà What to Do Next (Recommended Steps)\n",
    "1. Raise the threshold to improve precision\n",
    "Right now, you're labeling nearly every building as fire-prone. A better threshold balances recall and precision. Try:\n",
    "\n",
    "\n",
    "**2. Use rebalanced training (under/oversampling) + time-aware features\n",
    "Your feature set is improving. Once you merge in more external data (e.g. weather, interventions), you'll get better precision without compromising recall.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b24cac",
   "metadata": {},
   "source": [
    "‚úÖ Recommendation\n",
    "You need a better balance between recall and precision, especially if you're building a resource-planning or early warning system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48cec1",
   "metadata": {},
   "source": [
    " üß™ Test Thresholds in [0.3, 0.5] Range\n",
    "These thresholds usually yield better trade-offs in imbalanced cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [0.3, 0.35, 0.4, 0.45, 0.5]:\n",
    "    y_pred = (y_probs >= t).astype(int)\n",
    "    print(f\"Threshold: {t}\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92714f1b",
   "metadata": {},
   "source": [
    "‚úÖ Recommended Threshold: 0.45 or 0.5\n",
    "üîπ Use 0.5 if:\n",
    "You're okay missing ~40% of fires (recall = 60%)\n",
    "\n",
    "But you want higher precision and better overall accuracy\n",
    "\n",
    "üîπ Use 0.45 if:\n",
    "You want more recall (70%) and still get better precision than 0.3‚Äì0.4\n",
    "\n",
    "You're still early in prototyping and prefer recall over precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2664e0c",
   "metadata": {},
   "source": [
    "üî• Fire Risk Modeling: Which Metric Matters Most?\n",
    "‚úÖ Choose Recall (0.45 threshold) if:\n",
    "Goal: Identify as many high-risk buildings as possible.\n",
    "\n",
    "Why: You prefer to flag more potential risks (even with false alarms).\n",
    "\n",
    "Use Case: Fire department wants early alerts, prevention, or targeted inspections.\n",
    "\n",
    "Cost of Missing Fires (False Negatives) is high ‚Äî it's worse to miss a fire than to overpredict.\n",
    "\n",
    "Recommended Metric:\n",
    "\n",
    "Recall (focus on sensitivity)\n",
    "\n",
    "Optionally: F2-score (which emphasizes recall more than precision)\n",
    "\n",
    "‚úÖ Choose Precision/Accuracy (0.5 threshold) if:\n",
    "Goal: Only flag buildings where you are confident fire will occur.\n",
    "\n",
    "Why: You want to minimize false alarms ‚Äî perhaps inspections are expensive.\n",
    "\n",
    "Use Case: You only act if the risk is very real (limited resources).\n",
    "\n",
    "Cost of False Positives is high (e.g., unnecessary inspections waste time/money).\n",
    "\n",
    "Recommended Metric:\n",
    "\n",
    "Precision\n",
    "\n",
    "Overall Accuracy\n",
    "\n",
    "üí° Best Practice in Risk Modeling:\n",
    "Since fire is rare and high-cost, it's usually better to favor recall, especially in early stages of modeling:\n",
    "\n",
    "‚ö†Ô∏è ‚ÄúIt‚Äôs better to catch 70% of fire risks with a few false alarms than to miss half the actual fires.‚Äù\n",
    "\n",
    "‚úÖ Conclusion for You:\n",
    "Use threshold = 0.45, prioritize recall, and track F2-score to guide further model improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, fbeta_score\n",
    "\n",
    "# üî∏ Assumes y_test (true labels) and y_probs (predicted probabilities) already exist\n",
    "\n",
    "# Define thresholds to evaluate\n",
    "thresholds = [0.2, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "    \n",
    "    results.append({\n",
    "        \"Threshold\": threshold,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F2 Score\": f2\n",
    "    })\n",
    "\n",
    "# Create DataFrame to view results\n",
    "threshold_df = pd.DataFrame(results)\n",
    "threshold_df = threshold_df.sort_values(by=\"F2 Score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# üîç Show table sorted by F2 Score\n",
    "threshold_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b970ffe",
   "metadata": {},
   "source": [
    "Interpretation (Fire Risk Modeling by Location & Month):\n",
    "| Threshold | Precision | Recall | F2 Score  | Comment                                                     |\n",
    "| --------- | --------- | ------ | --------- | ----------------------------------------------------------- |\n",
    "| **0.50**  | 0.027     | 0.603  | **0.113** |  **Best F2 Score**: balances recall & tolerable precision |\n",
    "| 0.45      | 0.025     | 0.698  | 0.107     |  Higher recall but drops F2 slightly                      |\n",
    "| 0.40      | 0.023     | 0.774  | 0.102     |  More recall, still decent                                |\n",
    "| 0.35‚Äì0.20 | ‚Üì         | ‚Üë      | ‚Üì         |  Recall increases but F2 & precision drop too much        |\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370bbb4",
   "metadata": {},
   "source": [
    "üîç Recommendation for Monthly Fire Risk by Location:\n",
    "Use threshold = 0.50 as your current working value:\n",
    "\n",
    "It provides the highest F2 score, which prioritizes recall more than precision ‚Äî ideal for risk modeling (catch more true fires).\n",
    "\n",
    "Keeps false positives relatively lower than aggressive recall thresholds (like 0.2‚Äì0.3).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f61289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(threshold_df[\"Threshold\"], threshold_df[\"Precision\"], label=\"Precision\", marker='o')\n",
    "plt.plot(threshold_df[\"Threshold\"], threshold_df[\"Recall\"], label=\"Recall\", marker='o')\n",
    "plt.plot(threshold_df[\"Threshold\"], threshold_df[\"F2 Score\"], label=\"F2 Score\", marker='o')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision, Recall, and F2 Score vs Threshold\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e5cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ‚öôÔ∏è Apply threshold\n",
    "threshold = 0.50\n",
    "y_pred_50 = (y_probs >= threshold).astype(int)\n",
    "\n",
    "# üìä Compute confusion matrix\n",
    "cm_50 = confusion_matrix(y_test, y_pred_50)\n",
    "tn, fp, fn, tp = cm_50.ravel()\n",
    "\n",
    "# üñºÔ∏è Plot confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_50, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Fire\", \"Fire\"], yticklabels=[\"No Fire\", \"Fire\"])\n",
    "plt.title(f\"Confusion Matrix at Threshold = {threshold}\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# üìÑ Classification report\n",
    "print(f\"\\nClassification Report at Threshold = {threshold}:\\n\")\n",
    "print(classification_report(y_test, y_pred_50, digits=3))\n",
    "\n",
    "# üìå Optional: print raw values\n",
    "print(f\"True Negatives:  {tn:,}\")\n",
    "print(f\"False Positives: {fp:,}\")\n",
    "print(f\"False Negatives: {fn:,}\")\n",
    "print(f\"True Positives:  {tp:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475705ef",
   "metadata": {},
   "source": [
    "üìå Suggested Next Steps:\n",
    "Try threshold = 0.45 for slightly higher recall (~70%) and more TP.\n",
    "\n",
    "Investigate false positives:\n",
    "\n",
    "Are they spatially or temporally concentrated?\n",
    "\n",
    "Are they near real fires? ‚Üí might still be valuable.\n",
    "\n",
    "Try probabilistic risk scores instead of hard 0/1 labels for decision-making (e.g., ranking top 5% riskiest buildings each month).\n",
    "\n",
    "Add contextual features:\n",
    "\n",
    "Weather, previous nearby fires, building age, intervention history.\n",
    "\n",
    "Consider ensemble models to better separate classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd1f02",
   "metadata": {},
   "source": [
    "Recommended Ensemble Approaches\n",
    "1. XGBoost (Gradient Boosted Trees)\n",
    "Handles imbalance well with scale_pos_weight\n",
    "\n",
    "Captures nonlinear relationships & feature interactions\n",
    "\n",
    "Already in your codebase? ‚Üí Try tuning thresholds further.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d2056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Make sure these are dtype 'category'\n",
    "categorical_cols = [\"CATEGORIE_UEF\", \"NO_ARROND_ILE_CUM\"]\n",
    "for col in categorical_cols:\n",
    "    X_train[col] = X_train[col].astype(\"category\")\n",
    "    X_test[col] = X_test[col].astype(\"category\")\n",
    "\n",
    "# Create model with categorical support\n",
    "model = XGBClassifier(\n",
    "    enable_categorical=True,  # ‚úÖ Tell XGBoost to handle 'category' dtypes\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=(len(y_train[y_train==0]) / len(y_train[y_train==1])),\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e08bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Default threshold = 0.5\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd733020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model:\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a3658",
   "metadata": {},
   "source": [
    "üîç Interpretation of Results\n",
    "Class\tPrecision\tRecall\tF1-score\tSupport\n",
    "No Fire\t0.9903\t0.7436\t0.8494\t3,674,405\n",
    "Fire\t0.0243\t0.4665\t0.0461\t50,239\n",
    "\n",
    "‚úÖ High precision for \"No Fire\" class ‚Äî the model is very confident when predicting a \"0\".\n",
    "\n",
    "‚ö†Ô∏è Very low precision for \"Fire\" class ‚Äî many false positives.\n",
    "\n",
    "‚ö†Ô∏è Moderate recall for \"Fire\" class (~47%) ‚Äî the model catches fewer than half of actual fire months.\n",
    "\n",
    "‚ö†Ô∏è Overall accuracy is misleading (73.99%) due to class imbalance.\n",
    "\n",
    "‚ö†Ô∏è F1-score for fires is very low (0.0461) ‚Äî imbalance and prediction difficulty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1323d0ff",
   "metadata": {},
   "source": [
    "‚úÖ Recommendations\n",
    "1. Adjust the Threshold\n",
    "Your previous evaluations showed:\n",
    "\n",
    "At threshold = 0.45, recall can go above 69% with slightly lower precision.\n",
    "\n",
    "Use this if recall is more important than precision (which is likely for fire risk modeling).\n",
    "\n",
    "2. Try F2 Score Optimization\n",
    "Use F2 to focus more on recall than precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e35531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "best_f2 = 0\n",
    "best_t = 0.5\n",
    "for t in np.arange(0.2, 0.6, 0.05):\n",
    "    preds = (y_pred_proba >= t).astype(int)\n",
    "    f2 = fbeta_score(y_test, preds, beta=2)\n",
    "    if f2 > best_f2:\n",
    "        best_f2 = f2\n",
    "        best_t = t\n",
    "print(f\"‚úÖ Best Threshold by F2: {best_t} with F2 Score = {best_f2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccd0b7",
   "metadata": {},
   "source": [
    "‚úÖ Summary\n",
    "Best Threshold (by F2): 0.55\n",
    "\n",
    "F2 Score: 0.1026\n",
    "\n",
    "This means that at a threshold of 0.55:\n",
    "\n",
    "You're catching more true fire cases (higher recall).\n",
    "\n",
    "While precision remains low, this is acceptable in early warning systems.\n",
    "\n",
    "üìå What You Should Do Next\n",
    "üîπ 1. Recalculate Metrics at 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13649244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred_055 = (y_pred_proba >= 0.55).astype(int)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_055))\n",
    "print(classification_report(y_test, y_pred_055, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e6ac11",
   "metadata": {},
   "source": [
    "üîπ Metrics\n",
    "Metric\tClass 0 (No Fire)\tClass 1 (Fire)\n",
    "Precision\t0.9896\t0.0262\n",
    "Recall\t0.8081\t0.3780\n",
    "F1-score\t0.8897\t0.0490\n",
    "\n",
    "Accuracy: 80.2%\n",
    "\n",
    "Macro Avg F1: 0.469\n",
    "\n",
    "Weighted Avg F1: 0.878\n",
    "\n",
    "F2 Score (used for tuning): ‚âà 0.103\n",
    "\n",
    "üîç Interpretation for Fire Risk Modeling\n",
    "Goal\tThreshold = 0.55 Outcome\n",
    "Recall (catching fires)\t‚úÖ Improved: 37.8% fires detected\n",
    "False positives tolerated\t‚ö†Ô∏è Over 700k buildings misclassified as fire\n",
    "Tradeoff\tBetter recall for fire cases at cost of precision and FP load\n",
    "\n",
    "This threshold is reasonable if you're building a risk prioritization tool, not a strict classifier. You can use it to flag locations for inspection or prevention, not for punitive action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd11c9",
   "metadata": {},
   "source": [
    "1. Without Using Probabilities (Default Predict Method)\n",
    "Prediction: model.predict(X_test) ‚Üí uses default threshold = 0.5\n",
    "\n",
    "Evaluation:\n",
    "\n",
    "Class\tPrecision\tRecall\tF1-score\tSupport\n",
    "No Fire\t0.9903\t0.7436\t0.8494\t3,674,405\n",
    "Fire\t0.0243\t0.4665\t0.0461\t50,239\n",
    "Accuracy\t\t\t73.99%\t3,724,644\n",
    "Macro Avg\t0.5073\t0.6051\t0.4477\t\n",
    "Weighted Avg\t0.9783\t0.7399\t0.8379\t\n",
    "\n",
    "‚úÖ Pros:\n",
    "\n",
    "Straightforward to interpret.\n",
    "\n",
    "Reasonable recall for fires (~47%).\n",
    "\n",
    "‚ùå Cons:\n",
    "\n",
    "Very poor precision for fire predictions (~2.4%).\n",
    "\n",
    "Many false positives; not ideal for direct operational deployment.\n",
    "\n",
    "üîé 2. With Predicted Probabilities + Threshold Tuning\n",
    "Method: y_pred = (y_probs >= threshold).astype(int)\n",
    "\n",
    "Evaluated Thresholds: 0.2 ‚Üí 0.55\n",
    "\n",
    "üìå Optimal Threshold (based on F2 Score): 0.50‚Äì0.55\n",
    "\n",
    "üìà Example @ Threshold = 0.50\n",
    "Class\tPrecision\tRecall\tF1-score\tSupport\n",
    "No Fire\t0.9903\t0.7436\t0.8494\t3,674,405\n",
    "Fire\t0.027\t0.603\t0.051\t50,239\n",
    "F2 Score\t\t\t0.113\t\n",
    "\n",
    "üìà Example @ Threshold = 0.55\n",
    "Class\tPrecision\tRecall\tF1-score\tSupport\n",
    "No Fire\t0.9896\t0.8081\t0.8897\t3,674,405\n",
    "Fire\t0.0262\t0.378\t0.0490\t50,239\n",
    "F2 Score\t\t\t0.103\t\n",
    "\n",
    "‚úÖ Pros:\n",
    "\n",
    "Recall is tunable to fit operational priorities (e.g., early warning vs. high precision).\n",
    "\n",
    "You can optimize for F2-score, which favors recall (crucial in rare event detection).\n",
    "\n",
    "More flexible for deployment as risk score instead of binary yes/no.\n",
    "\n",
    "‚ùå Cons:\n",
    "\n",
    "Still limited precision.\n",
    "\n",
    "Requires communication around threshold logic in downstream applications.\n",
    "\n",
    "‚öñÔ∏è Summary Table\n",
    "Method\tPrecision (Fire)\tRecall (Fire)\tF1 (Fire)\tAccuracy\tBest Use Case\n",
    "predict() (default)\t0.0243\t0.4665\t0.0461\t73.99%\tFast baseline, needs interpretation\n",
    "predict_proba() + 0.50\t0.0270\t0.603\t0.051\t73.99%\tRecommended for alerting\n",
    "predict_proba() + 0.55\t0.0262\t0.378\t0.049\t80.2%\tGood compromise for precision/recall\n",
    "\n",
    "‚úÖ Recommendation\n",
    "Use predict_proba() + threshold tuning (e.g., 0.50‚Äì0.55):\n",
    "\n",
    "Enables risk ranking, not just binary prediction.\n",
    "\n",
    "Maximizes fire detection potential with acceptable false alarm rates.\n",
    "\n",
    "Better suited for real-world prioritization workflows like fire inspections, resource allocation, and prevention alerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da0392f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e199ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c30cbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
